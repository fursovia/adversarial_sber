{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List, Dict, Any, Sequence\n",
    "from itertools import chain\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import typer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Optional, Dict, Union\n",
    "from dataclasses_json import dataclass_json\n",
    "import torch\n",
    "from allennlp.data import TextFieldTensors\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from dataclasses_json import dataclass_json\n",
    "\n",
    "\n",
    "START_TOKEN = \"<START>\"\n",
    "END_TOKEN = \"<END>\"\n",
    "MASK_TOKEN = \"@@MASK@@\"\n",
    "\n",
    "\n",
    "@dataclass_json\n",
    "@dataclass\n",
    "class TransactionsData:\n",
    "    transactions: List[int]\n",
    "    amounts: List[float]\n",
    "    label: int\n",
    "    client_id: Optional[int] = None\n",
    "\n",
    "\n",
    "ModelsInput = Dict[str, Union[TextFieldTensors, torch.Tensor]]\n",
    "import torch\n",
    "import pickle\n",
    "import jsonlines\n",
    "import numpy as np\n",
    "from allennlp.data import Batch\n",
    "from allennlp.nn.util import move_to_device\n",
    "from allennlp.data.dataset_readers import DatasetReader\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "\n",
    "\n",
    "def data_to_tensors(\n",
    "    data: TransactionsData, reader: DatasetReader, vocab: Vocabulary, device: Union[torch.device, int] = -1\n",
    ") -> ModelsInput:\n",
    "\n",
    "    instances = Batch([reader.text_to_instance(**data.to_dict())])\n",
    "\n",
    "    instances.index_instances(vocab)\n",
    "    inputs = instances.as_tensor_dict()\n",
    "    return move_to_device(inputs, device)\n",
    "\n",
    "\n",
    "def decode_indexes(\n",
    "    indexes: torch.Tensor, vocab: Vocabulary, namespace=\"transactions\", drop_start_end: bool = True,\n",
    ") -> List[str]:\n",
    "    out = [vocab.get_token_from_index(idx.item(), namespace=namespace) for idx in indexes]\n",
    "\n",
    "    if drop_start_end:\n",
    "        return out[1:-1]\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def load_jsonlines(path: str) -> List[Dict[str, Any]]:\n",
    "    data = []\n",
    "    with jsonlines.open(path, \"r\") as reader:\n",
    "        for items in reader:\n",
    "            data.append(items)\n",
    "    return data\n",
    "\n",
    "\n",
    "def write_jsonlines(data: Sequence[Dict[str, Any]], path: str) -> None:\n",
    "    with jsonlines.open(path, \"w\") as writer:\n",
    "        for ex in data:\n",
    "            writer.write(ex)\n",
    "\n",
    "\n",
    "def generate_transaction_amounts(total_amount: float, num_transactions: int, alpha: float = 1.0) -> List[float]:\n",
    "    assert total_amount > 0\n",
    "    values = np.random.dirichlet(np.ones(num_transactions) * alpha, size=1) * total_amount\n",
    "    values = values.tolist()[0]\n",
    "    return values\n",
    "\n",
    "\n",
    "def load_discretizer(discretizer_path: str) -> KBinsDiscretizer:\n",
    "    with open(discretizer_path, \"rb\") as f:\n",
    "        discretizer: KBinsDiscretizer = pickle.load(f)\n",
    "        assert discretizer.encode == \"ordinal\"\n",
    "\n",
    "    return discretizer\n",
    "\n",
    "\n",
    "def transform_amounts(amounts: List[float], discretizer: KBinsDiscretizer) -> List[str]:\n",
    "    amounts = discretizer.transform([[x] for x in amounts])\n",
    "    # unpack and covert float -> int -> str\n",
    "    amounts = list(map(str, (map(int, chain(*amounts)))))\n",
    "    return amounts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install dataclasses-json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MultipleLocator\n",
    "def plot_statistics_concat(path, name: None ):\n",
    "    output = load_jsonlines(path)\n",
    "    output = pd.DataFrame(output).drop(columns=\"history\")\n",
    "    y_true = [output[\"data\"][i][\"transactions\"] for i in range(len(output))]\n",
    "    y_adv = [output[\"adversarial_data\"][i][\"transactions\"] for i in range(len(output))]\n",
    "    a_true = [output[\"data\"][i][\"amounts\"] for i in range(len(output))]\n",
    "    a_adv = [output[\"adversarial_data\"][i][\"amounts\"] for i in range(len(output))]\n",
    "    y_add_1 = [int(y_adv[i][len(y_adv[i])-1]) for  i in range(len(output))]\n",
    "    y_add_2 = [int(y_adv[i][len(y_adv[i])-2]) for i in range(len(output))]\n",
    "    a_add_1 = [a_adv[i][len(a_adv[i])-1] for  i in range(len(output))]\n",
    "    a_add_2 = [a_adv[i][len(a_adv[i])-2] for i in range(len(output))]\n",
    "    print(y_add_1, '\\n')\n",
    "    plt.figure(figsize=(400,100))\n",
    "    plt.suptitle('Distribution of added tokens by number: '+name, fontsize=320)\n",
    "    fig = plt.subplot(1, 4, 1)\n",
    "    fig.hist(sorted(y_add_1), 20)\n",
    "    fig.get_xaxis().set_major_locator(MultipleLocator(20))\n",
    "    fig.set_title('transaction_add1', fontsize = 200)\n",
    "    fig.set_xlabel('added tokens', fontsize = 160)\n",
    "    fig.tick_params(axis='x', which='major', labelsize=120)\n",
    "    fig.tick_params(axis='y', which='major', labelsize=120)\n",
    "# second subplot\n",
    "    fig = plt.subplot(1, 4, 2)\n",
    "    fig.hist(sorted(y_add_2), 5)\n",
    "    fig.get_xaxis().set_major_locator(MultipleLocator(20))\n",
    "    fig.set_title('transaction_add2', fontsize = 200)\n",
    "    fig.set_xlabel('added tokens', fontsize = 160)\n",
    "    fig.tick_params(axis='x', which='major', labelsize=120)\n",
    "    fig.tick_params(axis='y', which='major', labelsize=120)\n",
    "# third subplot\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.hist(sorted(a_add_1), 20)\n",
    "    plt.title('amounts_add1', fontsize = 200)\n",
    "    plt.xlabel('added tokens', fontsize = 160)\n",
    "    plt.tick_params(axis='y', which='major', labelsize=120)\n",
    "    plt.tick_params(axis='x', which='major', labelsize=120)\n",
    "# fourth subplot\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.hist(sorted(a_add_2),20)\n",
    "    plt.title('amounts_add2', fontsize = 200)\n",
    "    plt.xlabel('added tokens', fontsize = 160)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=120)\n",
    "    plt.savefig('Distribution_of_added_tokens_by_number_' +name+'.png')\n",
    "    plt.figure(figsize=(400,100))\n",
    "    plt.suptitle('Distribution of added tokens: '+ name, fontsize=320)\n",
    "    fig = plt.subplot(1, 2, 1)\n",
    "    fig.hist(sorted((y_add_1+y_add_2)), 180)\n",
    "    fig.set_title('transaction_ins', fontsize = 400)\n",
    "    fig.get_xaxis().set_major_locator(MultipleLocator(5))\n",
    "    fig.set_xlabel('added tokens', fontsize = 320)\n",
    "    fig.tick_params(axis='x', which='major', labelsize=240)\n",
    "    fig.tick_params(axis='y', which='major', labelsize=240)\n",
    "# second subplot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(sorted(a_add_1+a_add_2), 20)\n",
    "    plt.title('amounts_ins', fontsize = 400)\n",
    "    plt.xlabel('added tokens', fontsize = 320)\n",
    "    plt.tick_params(axis='x', which='major', labelsize=240)\n",
    "    plt.tick_params(axis='y', which='major', labelsize=240)\n",
    "    plt.savefig('Distribution_of_added_tokens_'+name+'.png')\n",
    "    #plt.show()\n",
    "    diversity = [(len(list(dict.fromkeys(y_add_1)))/len(y_add_1)+ len(list(dict.fromkeys(y_add_2)))/len(y_add_2))/2,len(list(dict.fromkeys(y_add_1+y_add_2)))/(len(y_add_1+y_add_2)),(len(list(dict.fromkeys(a_add_1)))/len(a_add_1)+len(list(dict.fromkeys(a_add_2)))/len(a_add_2))/2, len(list(dict.fromkeys(a_add_1+a_add_2)))/(len(a_add_1+a_add_2)) ]\n",
    "    return diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "diversity = plot_statistics_concat('gender_results_gru_con_sf/output.json', 'Concate_sf_gru_gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_statistics_nonconcat1(path, name: None ):\n",
    "    output = load_jsonlines(path)\n",
    "    output = pd.DataFrame(output).drop(columns=\"history\")\n",
    "    y_true = [output[\"data\"][i][\"transactions\"] for i in range(len(output))]\n",
    "    y_adv = [output[\"adversarial_data_target\"][i][\"transactions\"] for i in range(len(output))]\n",
    "    a_true = [output[\"data\"][i][\"amounts\"] for i in range(len(output))]\n",
    "    a_adv = [output[\"adversarial_data_target\"][i][\"amounts\"] for i in range(len(output))]\n",
    "    y_ins = []\n",
    "    y_num_ins = []\n",
    "    y_old = []\n",
    "    a_old = []\n",
    "    for i in range (len(output)):\n",
    "        k = len(y_ins)\n",
    "        #print((len(y_adv[i])))\n",
    "        for t in range (len(y_adv[i])):\n",
    "            #if (len(y_ins) == k+2):\n",
    "                #break\n",
    "            #print (len(y_adv[i]))\n",
    "            if (int(y_adv[i][t]) != int(y_true[i][t])):\n",
    "                y_ins.append(int(y_adv[i][t]))\n",
    "                y_old.append(int(y_true[i][t]))\n",
    "                y_num_ins.append(t)\n",
    "    plt.figure(figsize=(200,100))\n",
    "    plt.suptitle('Distribution_of_inserted_tokens: '+ name, fontsize=400)\n",
    "    fig = plt.subplot(1,1,1)\n",
    "    #plt.subplot(1, 2, 1)\n",
    "    fig.hist(y_ins, 180)\n",
    "    #plt.title('transaction_ins', fontsize = 100)\n",
    "    fig.set_xlabel('tokens', fontsize = 320)\n",
    "    fig.set_ylabel('quantity of insertions', fontsize = 320)\n",
    "    fig.tick_params(axis='both', which='major', labelsize=240)\n",
    "    fig.get_xaxis().set_major_locator(MultipleLocator(10))\n",
    "# second subplot\n",
    "    plt.savefig('Distribution_of_inserted_tokens_'+name+'.png')\n",
    "    return y_ins, y_old, y_num_ins\n",
    "#plt.subplot(1, 2, 1)\n",
    "def plot_statistics_nonconcat2(path, name, y_ins, y_old,  y_num_ins):\n",
    "    plt.figure(figsize=(200,100))\n",
    "    plt.suptitle('Inserted token(original token): '+ name, fontsize=400)\n",
    "    plt.plot(y_ins, y_old, 'ro', markersize = 100)\n",
    "    #plt.title('transactions', fontsize = 100)\n",
    "    plt.ylabel('inserted tokens', fontsize = 320)\n",
    "    plt.xlabel('old tokens', fontsize =320)\n",
    "    plt.savefig('Inserted_token(original_token)_'+name+'.png')\n",
    "    plt.tick_params(axis='x', which='major', labelsize=240)\n",
    "    plt.tick_params(axis='y', which='major', labelsize=240)\n",
    "    return 'Plot Inserted_token(original_token)'\n",
    "def plot_statistics_nonconcat3(path, name, y_ins, y_old,  y_num_ins):\n",
    "    plt.figure(figsize=(200,100))\n",
    "    plt.suptitle('Inserted token (num of changed token): '+ name, fontsize=400)\n",
    "    #plt.subplot(1, 2, 1)\n",
    "    plt.plot(y_num_ins, y_ins, 'ro', markersize = 30)\n",
    "    #plt.title('transactions', fontsize = 100)\n",
    "    plt.ylabel('inserted tokens', fontsize = 320)\n",
    "    plt.xlabel('number', fontsize =320)\n",
    "    plt.savefig('Inserted_token(num_of_changed_token)_'+name+'.png')\n",
    "    #plt.show()\n",
    "    plt.tick_params(axis='x', which='major', labelsize=240)\n",
    "    plt.tick_params(axis='y', which='major', labelsize=240)\n",
    "    diversity = [(len(list(dict.fromkeys(y_ins[::2])))/len(y_ins[::2])+len(list(dict.fromkeys(y_ins[1::2])))/len(y_ins[1::2]))/2,len(list(dict.fromkeys(y_ins)))/(len(y_ins)) ]\n",
    "    return diversity\n",
    "def plot_statistics_nonconcat4(path, name, y_ins, y_old,y_num_ins):\n",
    "    plt.figure(figsize=(200,100))\n",
    "    plt.suptitle('Quantity of inserted_token (num of changed token): '+ name, fontsize=400)\n",
    "    fig = plt.subplot(1,1,1)\n",
    "    fig.tick_params(axis='both', which='major', labelsize=240)\n",
    "    fig.get_xaxis().set_major_locator(MultipleLocator(10))\n",
    "    #plt.subplot(1, 2, 1)\n",
    "    fig.hist(y_num_ins, 20)\n",
    "    #plt.title('transactions', fontsize = 100)\n",
    "    fig.set_ylabel('quantity of inserted tokens', fontsize = 320)\n",
    "    fig.set_xlabel('number', fontsize =320)\n",
    "    plt.savefig('Quantity_Inserted_token(num_of_changed_token)_'+name+'.png')\n",
    "    return 'Plot Quantity_Inserted_token(num_of_changed_token)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_statistics_nonconcat(path, name):\n",
    "    y_ins, y_old, y_num_ins= plot_statistics_nonconcat1(path,name)\n",
    "    diversity = plot_statistics_nonconcat3(path,name, y_ins, y_old, y_num_ins)\n",
    "    p = plot_statistics_nonconcat2(path,name,y_ins, y_old, y_num_ins)\n",
    "    d = plot_statistics_nonconcat4(path,name, y_ins, y_old, y_num_ins)\n",
    "    return diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(plot_statistics_nonconcat('gru_age.json','779'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('J')\n",
    "diversity_age_results_gru_fgsm = plot_statistics_nonconcat('age_results_gru_fgsm/output_substitute2.json', 'FGSM_age_results_gru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "diversity_age_results_lstm_fgsm=plot_statistics_nonconcat('age_results_lstm_fgsm/output_substitute2.json', 'FGSM_age_results_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diversity_age_results__gru_fgsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diversity_age_results_rnn_fgsm=plot_statistics_nonconcat('age_results_rnn_fgsm/output_substitute2.json', 'FGSM_age_results_rnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

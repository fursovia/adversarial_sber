{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import json\n",
    "import jsonlines\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from advsber.utils.data import write_jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_weeks = 10\n",
    "DATASET_NAME = 'gender'\n",
    "DATASET_READ_PATH = \"../data\"\n",
    "DATASET_SAVE_PATH = 'datasets'\n",
    "index= n_weeks\n",
    "NUM_WEEKS = 24//n_weeks\n",
    "MIN_LEN = 3\n",
    "MAX_LEN = 50*n_weeks\n",
    "TEST_RATIO = 0.1\n",
    "SUBST_RATIO = 0.3\n",
    "VALID_RATIO = 0.2\n",
    "LM_RATIO = 0.1\n",
    "NUM_DAYS = 7*n_weeks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET_NAME == 'age':\n",
    "    data = pd.read_csv(f'{DATASET_READ_PATH}/{DATASET_NAME}/transactions_train.csv')\n",
    "    target_data = pd.read_csv(f'{DATASET_READ_PATH}/{DATASET_NAME}/train_target.csv')\n",
    "    data['week'] = data['trans_date'] // NUM_DAYS\n",
    "else:\n",
    "    transactions = pd.read_csv(f'{DATASET_READ_PATH}/{DATASET_NAME}/transactions.csv')\n",
    "    target_data = pd.read_csv(f'{DATASET_READ_PATH}/{DATASET_NAME}/gender_train.csv')\n",
    "    data = transactions.rename(columns={'customer_id': 'client_id', 'amount':'amount_rur'})\n",
    "    target_data = target_data.rename(columns={'customer_id':'client_id', 'gender':'bins'})\n",
    "    data['week'] = data['tr_datetime'].str.split(' ').apply(lambda x: int(x[0]) // 7)\n",
    "    data['small_group'] = data['mcc_code'].tolist()\n",
    "target_data_dict = dict(target_data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = data.groupby(['client_id', 'week']).agg(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lovely_data_raw = []\n",
    "\n",
    "for idx, (_, row) in tqdm(enumerate(transactions.iterrows())):\n",
    "    client_id, week = row.name\n",
    "\n",
    "    my_lovely_data_raw.append(\n",
    "        {\n",
    "            'transactions': row['small_group'],\n",
    "            'amounts': row.amount_rur,\n",
    "            'client_id': client_id, \n",
    "            'week': week\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lovely_data = pd.DataFrame(my_lovely_data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lovely_data = my_lovely_data[(my_lovely_data['week'] < NUM_WEEKS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lovely_data['label'] = my_lovely_data['client_id'].apply(lambda x: target_data_dict.get(x))\n",
    "my_lovely_data = my_lovely_data[~my_lovely_data['label'].isna()]\n",
    "my_lovely_data['label'] = my_lovely_data['label'].astype(int)\n",
    "my_lovely_data = my_lovely_data[['transactions', 'amounts', 'client_id', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = my_lovely_data.transactions.apply(lambda x: len(x))\n",
    "\n",
    "my_lovely_data = my_lovely_data[(lens >= MIN_LEN) & (lens <= MAX_LEN)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_train, lm_valid = train_test_split(\n",
    "    my_lovely_data, \n",
    "    stratify=my_lovely_data['label'], \n",
    "    random_state=126663,\n",
    "    test_size=LM_RATIO\n",
    ")\n",
    "\n",
    "other_data, test_data = train_test_split(\n",
    "    my_lovely_data, \n",
    "    stratify=my_lovely_data['label'], \n",
    "    random_state=123,\n",
    "    test_size=TEST_RATIO\n",
    ")\n",
    "\n",
    "target_data, subst_data = train_test_split(\n",
    "    other_data, \n",
    "    stratify=other_data['label'], \n",
    "    random_state=123,\n",
    "    test_size=SUBST_RATIO\n",
    ")\n",
    "\n",
    "target_data_tr, target_data_val = train_test_split(\n",
    "    target_data, \n",
    "    stratify=target_data['label'], \n",
    "    random_state=123,\n",
    "    test_size=VALID_RATIO\n",
    ")\n",
    "\n",
    "subst_data_tr, subst_data_val = train_test_split(\n",
    "    subst_data, \n",
    "    stratify=subst_data['label'], \n",
    "    random_state=123,\n",
    "    test_size=VALID_RATIO\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NAME =DATASET_SAVE_PATH+'/' + DATASET_NAME + '_' + str(index)\n",
    "!mkdir \"$DATASET_SAVE_PATH\"\n",
    "!mkdir \"$NAME\"\n",
    "!mkdir \"$NAME/target_clf\"\n",
    "!mkdir \"$NAME/substitute_clf\"\n",
    "!mkdir \"$NAME/lm\"\n",
    "write_jsonlines(test_data.to_dict('records'), f'{DATASET_SAVE_PATH}/{DATASET_NAME}_{index}/test.jsonl')\n",
    "\n",
    "write_jsonlines(target_data_tr.to_dict('records'), f'{DATASET_SAVE_PATH}/{DATASET_NAME}_{index}/target_clf/train.jsonl')\n",
    "write_jsonlines(target_data_val.to_dict('records'), f'{DATASET_SAVE_PATH}/{DATASET_NAME}_{index}/target_clf/valid.jsonl')\n",
    "\n",
    "write_jsonlines(subst_data_tr.to_dict('records'), f'{DATASET_SAVE_PATH}/{DATASET_NAME}_{index}/substitute_clf/train.jsonl')\n",
    "write_jsonlines(subst_data_val.to_dict('records'), f'{DATASET_SAVE_PATH}/{DATASET_NAME}_{index}/substitute_clf/valid.jsonl')\n",
    "\n",
    "write_jsonlines(lm_train.to_dict('records'), f'{DATASET_SAVE_PATH}/{DATASET_NAME}_{index}/lm/train.jsonl')\n",
    "write_jsonlines(lm_valid.to_dict('records'), f'{DATASET_SAVE_PATH}/{DATASET_NAME}_{index}/lm/valid.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import json\n",
    "import jsonlines\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data for language model (LM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘../../ageN’: File exists\n",
      "mkdir: cannot create directory ‘../../ageN/lm’: File exists\n",
      "mkdir: cannot create directory ‘../../ageN/target_clf’: File exists\n",
      "mkdir: cannot create directory ‘../../ageN/substitute_clf/’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir ../../age\n",
    "!mkdir ../../age/lm\n",
    "!mkdir ../../age/target_clf\n",
    "!mkdir ../../age/substitute_clf/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/age/transactions_train.csv')\n",
    "target_data = pd.read_csv('../data/age/train_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_slice_subsample(sub_data, cnt_min, cnt_max, split_count):\n",
    "    sub_datas = []\n",
    "    for i in range(0, split_count):\n",
    "        T_i = np.random.randint(cnt_min, cnt_max)\n",
    "        s = np.random.randint(0, len(sub_data)-T_i-1)\n",
    "        S_i = sub_data[s:s+T_i-1]\n",
    "        sub_datas.append(S_i)\n",
    "            \n",
    "    return sub_datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_set(name, data, target):\n",
    "    len_ = len(np.unique(target.client_id))\n",
    "    dict_data = {}\n",
    "    with jsonlines.open(name, \"w\") as writer:\n",
    "        S = 0\n",
    "        for index, client_id in enumerate(np.unique(target.client_id)):\n",
    "            sys.stdout.write(\"\\r %d out of %d\" % (index, len_))\n",
    "\n",
    "            sub_data = data[data['client_id']==client_id]\n",
    "            sub_data_target = target[target['client_id']==client_id]\n",
    "\n",
    "            sub_datas = split_slice_subsample(sub_data, 50, 200, 30)\n",
    "\n",
    "            for loc_data in sub_datas:\n",
    "                loc_dict = {\"transactions\": list(loc_data.small_group),\n",
    "                            \"amounts\": list(loc_data.amount_rur),\n",
    "                            \"label\": int(sub_data_target.bins),\n",
    "                            \"client_id\": int(client_id)}\n",
    "                S = S+ len(loc_data.small_group)\n",
    "                writer.write(loc_dict) \n",
    "                \n",
    "    print('mean length:', S/(len(sub_datas)* len((np.unique(target.client_id)))))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_lm(data, target_data):\n",
    "    target_data_train, target_data_valid = train_test_split(target_data, test_size=0.2, random_state=10, shuffle=True)\n",
    "    print('Create train set...')\n",
    "    create_set('../../age/lm/train.jsonl', data, target_data_train)\n",
    "    print('Create valid set...')\n",
    "    create_set('../../age/lm/valid.jsonl', data, target_data_valid)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create train set...\n",
      " 23999 out of 24000mean length: 85.98383472222223\n",
      "Create valid set...\n",
      " 5999 out of 6000mean length: 85.97567222222222\n"
     ]
    }
   ],
   "source": [
    "split_data_lm(data, target_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data for classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘substitute_clf’: File exists\n",
      "mkdir: cannot create directory ‘target_clf’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir substitute_clf\n",
    "!mkdir target_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data_test_sub, target_data_targetclf = train_test_split(target_data, test_size=0.65, random_state=10, shuffle=True)\n",
    "target_data_subclf, target_data_test = train_test_split(target_data_test_sub, test_size=2./7, random_state=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘substitute_clf’: File exists\n",
      "mkdir: cannot create directory ‘target_clf’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir substitute_clf\n",
    "!mkdir target_clf\n",
    "target_data_test_sub, target_data_targetclf = train_test_split(target_data, test_size=0.65, random_state=10, shuffle=True)\n",
    "target_data_subclf, target_data_test = train_test_split(target_data_test_sub, test_size=2./7, random_state=10, shuffle=True)\n",
    "def split_data(data, target_data, dir_):\n",
    "    target_data_train, target_data_valid = train_test_split(target_data, test_size=0.2, random_state=10, shuffle=True)\n",
    "    print('Create train set...')\n",
    "    create_set(dir_+'/'+'train.jsonl', data, target_data_train)\n",
    "    print('Create valid set...')\n",
    "    create_set(str(dir_)+'/'+'valid.jsonl', data, target_data_valid)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2999 out of 3000mean length: 86.15154444444444\n"
     ]
    }
   ],
   "source": [
    "#create test set for both target and substitute classifiers\n",
    "create_set('age_test.jsonl', data, target_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create train set...\n",
      " 5999 out of 6000mean length: 86.02505555555555\n",
      "Create valid set...\n",
      " 1499 out of 1500mean length: 86.15308888888889\n"
     ]
    }
   ],
   "source": [
    "#create valid and train data for substitute classifier\n",
    "split_data(data, target_data_subclf, '../../age/substitute_clf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create train set...\n",
      " 15599 out of 15600mean length: 86.03875427350427\n",
      "Create valid set...\n",
      " 3899 out of 3900mean length: 85.93957264957265\n"
     ]
    }
   ],
   "source": [
    "#create valid and train data for target classifier\n",
    "split_data(data, target_data_targetclf, '../../age/target_clf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
